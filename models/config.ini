[NER_Training]
models = DTAI-KULeuven/robbert-2022-dutch-base, wietsedv/bert-base-dutch-cased, bert-base-multilingual-cased, distilbert-base-multilingual-cased
learning_rate = 3e-6, 3e-5, 5e-6, 5e-5
max_epochs = 10,15,20,30
mini_batch_size = 16,32
output_folder = .
fine_tune = True, False
fine_tune_layers = -1  # "-1" for the last layer, "-1,-2" for the last two layers, etc.

[REL_Training]
models = DTAI-KULeuven/robbert-2022-dutch-base, wietsedv/bert-base-dutch-cased, bert-base-multilingual-cased, distilbert-base-multilingual-cased
learning_rate = 3e-6, 3e-5, 5e-6, 5e-5
max_epochs = 10,15,20,30
mini_batch_size = 16,32
output_folder = .
fine_tune = True, False
fine_tune_layers = -1  # "-1" for the last layer, "-1,-2" for the last two layers, etc.
